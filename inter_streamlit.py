from gensim.models import Word2Vec
import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import re 
from collections import defaultdict
import pandas as pd
import folium
from streamlit_folium import folium_static
from folium import plugins
from googletrans import Translator
from PIL import Image
import seaborn as sns
import plotly.express as px
from meta import * # file with long texts
#spreadsheet check
# from gsheetsdb import connect
# from gspread_pandas import Spread,Client
# from google.oauth2 import service_account



st.set_page_config(layout="wide")

#Create a Google Authentication connection object
# scope = ['https://spreadsheets.google.com/feeds',
#          'https://www.googleapis.com/auth/drive']

# credentials = service_account.Credentials.from_service_account_info(
#                 st.secrets["gcp_service_account"], scopes = scope)
# client = Client(scope=scope,creds=credentials)
# spreadsheetname = "Input_holder"
# spread = Spread(spreadsheetname,client = client)


#mean vectorizer
class MeanEmbeddingVectorizer(object):
    def __init__(self, model_cbow):
        self.model_cbow = model_cbow
        self.vector_size = model_cbow.wv.vector_size

    def fit(self):  
        return self

    def transform(self, docs): 
        doc_word_vector = self.doc_average_list(docs)
        return doc_word_vector

    def doc_average(self, doc):
        mean = []
        for word in doc:
            if word in self.model_cbow.wv.index_to_key:
                mean.append(self.model_cbow.wv.get_vector(word))

        if not mean: 
            return np.zeros(self.vector_size)
        else:
            mean = np.array(mean).mean(axis=0)
            return mean

    def doc_average_list(self, docs):
        return np.vstack([self.doc_average(doc) for doc in docs])

#tf-idf vectorized
class TfidfEmbeddingVectorizer(object):
    def __init__(self, model_cbow):

        self.model_cbow = model_cbow
        self.word_idf_weight = None
        self.vector_size = model_cbow.wv.vector_size

    def fit(self, docs): 


        text_docs = []
        for doc in docs:
            text_docs.append(" ".join(doc))

        tfidf = TfidfVectorizer()
        tfidf.fit(text_docs)  
        # if a word was never seen it is given idf of the max of known idf value
        max_idf = max(tfidf.idf_)  
        self.word_idf_weight = defaultdict(
            lambda: max_idf,
            [(word, tfidf.idf_[i]) for word, i in tfidf.vocabulary_.items()],
        )
        return self

    def transform(self, docs): 
        doc_word_vector = self.doc_average_list(docs)
        return doc_word_vector

    def doc_average(self, doc):


        mean = []
        for word in doc:
            if word in self.model_cbow.wv.index_to_key:
                mean.append(
                    self.model_cbow.wv.get_vector(word) * self.word_idf_weight[word]
                ) 

        if not mean:  
            return np.zeros(self.vector_size)
        else:
            mean = np.array(mean).mean(axis=0)
            return mean
    def doc_average_list(self, docs):
      return np.vstack([self.doc_average(doc) for doc in docs])

@st.cache(allow_output_mutation=True)
def load_data(check): 
    if check: 
        data = pd.read_excel('main_data-2-2_copy (1).xlsx', index_col=0)
        embeddings = pd.read_pickle('embed.pickle')
        clean_words = pd.read_pickle('words.pickle')
        swords = pd.read_pickle('swords.pickle')
        latlong = pd.read_csv('LATandLONG.csv', index_col=0)
        progs = pd.read_pickle('nwconstr.pickle')
    return data, embeddings, clean_words, swords, latlong, progs
data, doc_vec, clean_words, swords, latlong, progs = load_data(True)
data = data[data['tuition_EUR']<90000] #looks shitty, but i don't have ehough time... haha)

# @st.cache(allow_output_mutation=True)
# def corpus_l(data):
#     return list(data)

@st.cache(allow_output_mutation=True)
def load_model(mpath): 
    return Word2Vec.load(mpath)

#load up some cleaning functions
def tokenization(text):
    tokens = re.split('\s+',text)
    return tokens

def remove_stopwords(text):
    output= [i for i in text if i not in swords]
    return output

def len_control(text):
  lemm_text = [word for word in text if len(word)>=3]
  return lemm_text

def sorter(text):
  sorted_list = sorted(text)
  return sorted_list

def make_clickable(name, link):
    # target _blank to open new window
    # extract clickable text to display for your link
    text = name
    return f'<a target="_blank" href="{link}">{text}</a>'

def program_parser2(data):
    for i in range(data.shape[0]):
        data.Introduction[i] = str(re.sub('[0-9]+',' ',re.sub(r'[^\w\s]',' ',re.sub('\\\\n', ' ' ,re.sub('&.*?;.*?;|&.*?;|._....',' ',str(data.Introduction[i]))))).lower().strip())
    data['msg_sorted_clean']= (data['Introduction']
                               .apply(lambda x: tokenization(x))
                               .apply(lambda x:remove_stopwords(x))
                               .apply(lambda x:len_control(x))
                               .apply(lambda x: sorter(x)))
    return data

def pick_n_pretty(df):
    output = df[['Link', 'program', 'university', 'country', 'city', 'language', 'tuition_EUR','Score']]
    output["Link"] = output.apply(
            lambda row: make_clickable(row["program"], row["Link"]), axis=1)
    output['tuition_EUR'] = output['tuition_EUR'].fillna(0)
    output['tuition_EUR'] = output.apply(lambda row: int(row['tuition_EUR']), axis=1)
    return output#.style.applymap(lambda x: "background-color: red" if x==0 else "background-color: white")


def get_recommendations(N, scores, data_path = 'main_data-2-2_copy (1).xlsx'):
    top = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:N]
    data = (pd.read_excel(data_path, index_col = 0)
           .drop(columns = ['msg_sorted_clean'])
           .loc[top]
           .reset_index())
    data['Score'] = sorted(scores, reverse=True)[:N]
    return data

def get_recs(sentence, N=10, mean=False):
    '''Get top-N recommendations based on your input'''
    input = pd.DataFrame({'Introduction': [str(sentence)]})
    input = program_parser2(input)
    input_embedding = tfidf_vec_tr.transform([input['msg_sorted_clean'][0]])[0].reshape(1, -1)
    cos_sim = map(lambda x: cosine_similarity(input_embedding, x)[0][0], doc_vec)
    scores = list(cos_sim)
    recommendations = get_recommendations(N,scores)
    return recommendations

def mfap(recs1, df=latlong):
    latlong = recs1.merge(df, left_on='city', right_on='location', how = 'inner')      
    uni_locations = latlong[["lat", "long", "location"]]
    map = folium.Map(location=[uni_locations.lat.mean(), uni_locations.long.mean()], zoom_start=4, control_scale=True)
    for index, location_info in uni_locations.iterrows():
        folium.Marker([location_info["lat"], location_info["long"]], popup=location_info["location"]).add_to(map)
    return map

def mfap_density_50(recs50, df=latlong): #try this function on the main page
    latlong = recs50.merge(df, left_on='city', right_on='location', how = 'inner')
    uni_locations = latlong[["lat", "long"]]
    map = folium.Map(location=[uni_locations.lat.mean(), uni_locations.long.mean()], zoom_start=4, control_scale=True)
    cityArr = uni_locations.values
    map.add_child(plugins.HeatMap(cityArr, radius=25))
    return map

def sim_prog(df=progs, prog=None):
    df_one = df[df['Program1']==prog]
    return df_one.sort_values(by='cosine', ascending=False)
#yes.... the code is suboptimal, but i don't care about image.pngs point now ;)
def p2p_locs(latlong=latlong, uni_info=data, recs=[], N=5): #recs is the output of sim_progs #density map for similar universities
    recs[['Uni', 'Prog']] = recs['Program2'].str.split(': ', 1, expand=True)
    recs[['Uni1', 'Prog1']] = recs['Program1'].str.split(': ', 1, expand=True)
    ps = (recs
            .merge(uni_info, left_on=['Uni', 'Prog'], right_on=['university','program'], how = 'inner')
            .merge(latlong, left_on='city', right_on='location', how ='inner'))
    fin_rec = ps[['Program1', 'Program2', 'city','cosine']].reset_index().iloc[1:N+1,:]
    uni_locations = ps[["lat", "long"]]
    map = folium.Map(location=[uni_locations.lat.mean(), uni_locations.long.mean()], zoom_start=4, control_scale=True)
    cityArr = uni_locations.values
    map.add_child(plugins.HeatMap(cityArr, radius=25))
    return map, fin_rec, ps 

def simple_output(map=True):
    col1, col2, col3 = st.columns([10, 10, 10])
    with col2:
        gif_runner = st.image("200.gif")
    recs1 = get_recs(str(text), N=int(number), mean=False)
    recs50 = get_recs(str(text), N=50, mean=False)
    recs1 = pick_n_pretty(recs1)
    gif_runner.empty()
    df = recs1.style.background_gradient(
        cmap=cmGreen,
        subset=[
            "Score",
        ],
    )
    st.write(df.to_html(escape=False), unsafe_allow_html=True)  
    if map:
        map2 = mfap_density_50(recs50) 
        map  = mfap(recs1)
        st.write('')
        st.write('')
        with st.expander('ÐŸÐ¾ÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒ Ð¸Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ ÐºÐ°Ñ€Ñ‚Ñ‹ ðŸŒ'):
            ce, c1, ce, c2, c3 = st.columns([0.07, 4, 0.07, 4, 0.07])
            with c1:
                st.write('Ð Ð°ÑÐ¿Ð¾Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ð·Ð°Ð¿Ñ€Ð°ÑˆÐ¸Ð²Ð°ÐµÐ¼Ñ‹Ñ… ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð¾Ð²')
                folium_static(map, width=450) 
            with c2:
                st.write('POI-Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð³Ð¾Ñ€Ð¾Ð´Ð¾Ð² Ñ‚Ð¾Ð¿-50 ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ñ… Ð’Ð°ÑˆÐµÐ¼Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÑƒ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼')
                folium_static(map2, width=450)


with st.sidebar:
    col1, col2, col3 =st.columns([2.2, 6, 2.2])
    with col1:
        st.write("")
    with col2:
        st.image('keystone-masters-degree.jpg') 
    with col3:
        st.write('')
    page = st.radio('Ð¡Ñ‚Ñ€Ð°Ð½Ð¸Ñ†Ð°', ['ÐŸÑ€Ð¸Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸ÐµðŸ‘‹',"ÐÐ°Ð¹Ñ‚Ð¸ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼ÑƒðŸŒ", "ÐÐ°Ð¹Ñ‚Ð¸ ÑÑ…Ð¾Ð¶Ð¸Ðµ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñ‹ðŸ™Œ","Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð¸ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°ðŸ“ˆ"])
    
    # st.subheader('Ð’Ñ‹Ð±ÐµÑ€Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹')
    # location = st.multiselect('Ð¡Ñ‚Ñ€Ð°Ð½Ð°', list(set(data['country'])))
    # on_site = st.selectbox('Ð¢ÐµÐ¼Ð¿ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ', ['ÐžÑ‡Ð½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ', 'Ð—Ð°Ð¾Ñ‡Ð½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ','ÐžÑ‡Ð½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ|Ð—Ð°Ð¾Ñ‡Ð½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ'])
    # pace = st.selectbox('Ð¤Ð¾Ñ€Ð¼Ð° Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ', ['ÐžÐ½Ð»Ð°Ð¹Ð½', 'ÐšÐ°Ð¼Ð¿ÑƒÑ','ÐšÐ°Ð¼Ð¿ÑƒÑ|ÐžÐ½Ð»Ð°Ð¹Ð½'])
    # lang = st.selectbox('Ð¤Ð¾Ñ€Ð¼Ð° Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ', list(set(data['Language'].dropna())))
    # cost = st.slider('Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ, EUR', int(data['tuition_EUR'].min()), int(data['tuition_EUR'].max()), (0, 3000), step=50)

# Page 1-Intro
if page=='ÐŸÑ€Ð¸Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸ÐµðŸ‘‹':
    #_max_width_()
    c30, c31, c32 = st.columns([2.5, 1, 3])

    with c30:
        st.image("keystone-masters-degree.jpg", width=400)
    

    st.markdown("""
            Ð”Ð¾Ð±Ñ€Ð¾ Ð¿Ð¾Ð¶Ð°Ð»Ð¾Ð²Ð°Ñ‚ÑŒ, Ð´Ð¾Ñ€Ð¾Ð³Ð¾Ð¹ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ!
            
            Ð ÐµÑˆÐ¸Ð» Ð½Ðµ Ð¾ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°Ñ‚ÑŒÑÑ Ð½Ð° Ð±Ð°ÐºÐ°Ð»Ð°Ð²Ñ€Ð¸Ð°Ñ‚Ðµ Ð¸ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð¸Ñ‚ÑŒ Ð³Ñ€Ñ‹Ð·Ñ‚ÑŒ Ð³Ñ€Ð°Ð½Ð¸Ñ‚ Ð½Ð°ÑƒÐºÐ¸ Ð² Ð¼Ð°Ð³Ð¸ÑÑ‚Ñ€Ð°Ñ‚ÑƒÑ€Ðµ? Ð—Ð½Ð°Ñ‡Ð¸Ñ‚, Ñ‚Ñ‹ Ð¿Ð¾ Ð²ÐµÑ€Ð½Ð¾Ð¼Ñƒ Ð°Ð´Ñ€ÐµÑÑƒ!

            ÐœÑ‹ Ð¿Ñ€ÐµÐ´Ð»Ð°Ð³Ð°ÐµÐ¼ Ñ‚ÐµÐ±Ðµ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¼Ð°Ð³Ð¸ÑÑ‚ÐµÑ€ÑÐºÐ¸Ñ… Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼ Ñ€Ð¾ÑÑÐ¸Ð¹ÑÐºÐ¸Ñ… Ð¸ Ð·Ð°Ñ€ÑƒÐ±ÐµÐ¶Ð½Ñ‹Ñ… ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð¾Ð² Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ‚Ð²Ð¾Ð¸Ñ… Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ñ‡Ñ‚ÐµÐ½Ð¸Ð¹!

            Ð¡Ð°Ð¹Ñ‚ Ð¿Ñ€ÐµÐ´Ð½Ð°Ð·Ð½Ð°Ñ‡ÐµÐ½ Ð´Ð»Ñ Ñ‚ÐµÑ…, ÐºÑ‚Ð¾ Ð¶ÐµÐ»Ð°ÐµÑ‚ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð¸Ñ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ, Ð½Ð¾ Ð¸ÑÐ¿Ñ‹Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ñ‚Ñ€ÑƒÐ´Ð½Ð¾ÑÑ‚Ð¸ Ð² Ð¿Ð¾Ð¸ÑÐºÐµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰ÐµÐ¹ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñ‹, ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð° Ð¸Ð»Ð¸ ÑÑ‚Ñ€Ð°Ð½Ñ‹.
        """, unsafe_allow_html = True)

    with st.expander("â„¹ï¸ - Ð˜Ð´ÐµÑ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°", expanded=False):

        st.markdown(
            """ 
ÐÐµÑÐ¼Ð¾Ñ‚Ñ€Ñ Ð½Ð° Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð² ÑÐ²Ð¾Ð¸Ñ… Ñ€Ð¾Ð´Ð½Ñ‹Ñ… Ð³Ð¾Ñ€Ð¾Ð´Ð°Ñ…, Ð½Ð°Ð±Ð»ÑŽÐ´Ð°ÐµÑ‚ÑÑ ÑÑ‚Ñ€ÐµÐ¼Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ ÑƒÐ²ÐµÐ»Ð¸Ñ‡ÐµÐ½Ð¸Ðµ Ñ‡Ð¸ÑÐ»Ð° ÑÑ‚ÑƒÐ´ÐµÐ½Ñ‚Ð¾Ð² Ð¸Ð· Ð¡ÐÐ“, Ð¶ÐµÐ»Ð°ÑŽÑ‰Ð¸Ñ… Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð±Ð¾Ð»ÑŒÑˆÐµ Ñ„Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ 'ÐºÐ¾Ñ€Ð¾Ñ‡ÐºÐ¸' Ð¾ ÐºÐ°ÐºÐ¾Ð¹-Ð»Ð¸Ð±Ð¾ ÑÑ‚ÐµÐ¿ÐµÐ½Ð¸. Ð’Ñ‹Ð±Ð¾Ñ€ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð° Ð·Ð° Ð¿Ñ€ÐµÐ´ÐµÐ»Ð°Ð¼Ð¸ ÑÐ²Ð¾ÐµÐ³Ð¾ Ð³Ð¾Ñ€Ð¾Ð´Ð°, Ð¸ Ð´Ð°Ð¶Ðµ ÑÑ‚Ñ€Ð°Ð½Ñ‹, Ð½Ðµ Ð·Ð°ÐºÐ°Ð½Ñ‡Ð¸Ð²Ð°ÐµÑ‚ÑÑ Ñ„Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³Ð°Ð¼Ð¸, ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒÑŽ Ð¸ Ð´Ñ€ÑƒÐ³Ð¸Ð¼Ð¸ Ð¸Ð·Ð¼ÐµÑ€Ð¸Ð¼Ñ‹Ð¼Ð¸ Ñ„Ð°ÐºÑ‚Ð¾Ñ€Ð°Ð¼Ð¸. *ÐŸÐ¾ ÑÑ‚Ð¾Ð¹ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ðµ, Ð½Ð°ÑˆÐ° Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð½Ð°Ñ Ð³Ñ€ÑƒÐ¿Ð¿Ð° Ð·Ð°Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ¾Ð²Ð°Ð»Ð°ÑÑŒ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒÑŽ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸ Ð½Ð°Ð¹Ñ‚Ð¸ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ð±Ð»Ð¸Ð·ÐºÐ¾Ðµ Ðº ÑÐ²Ð¾Ð¸Ð¼ Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ñ‡Ñ‚ÐµÐ½Ð¸ÑÐ¼ Ð½Ðµ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¼, Ð½Ð¾ Ð¸ Ð¼ÐµÐ½ÐµÐµ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ñ‹Ð¼ Ð² ÑÐµÐ±Ðµ ÑÐ»ÑƒÑˆÐ°Ñ‚ÐµÐ»ÑÐ¼.* ÐÐ°ÑˆÐ° ÑÐ¸ÑÑ‚ÐµÐ¼Ð° ÑÐ¾ÑÑ‚Ð¾Ð¸Ñ‚ Ð¸Ð· Ñ‡ÐµÑ‚Ñ‹Ñ€ÐµÑ… ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð±Ñ‹Ð»Ð¸ Ð¿Ð¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ñ‹ Ð¿Ð¾ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð½Ð¾Ð¹ Ð»Ð¾Ð³Ð¸ÐºÐµ:

1. ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ ÑÐ½Ð°Ñ‡Ð°Ð»Ð° Ð¾Ð·Ð½Ð°ÐºÐ°Ð¼Ð»Ð¸Ð²Ð°ÐµÑ‚ÑÑ Ñ Ð±Ð»Ð¸Ð·ÐºÐ¸Ð¼Ð¸ Ðº ÐµÐ³Ð¾ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸ÑŽ ÑÐ²Ð¾Ð¸Ñ… ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚ÐµÐ¹, Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ¾Ð² Ð¸ Ð¶ÐµÐ»Ð°Ð½Ð¸Ð¹ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð°Ð¼Ð¸ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¾Ñ‡ÐµÐ²Ð¸Ð´Ð½Ñ‹Ñ… Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ€Ð¾Ð², Ð»Ð¾ÐºÐ°Ñ†Ð¸Ð¹ Ð¸ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ñ ÑÐ°Ð¹Ñ‚Ð° Keystone (Ð½Ð° ÑÑ€Ð°Ð½Ð¸Ñ†Ñ‹ ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð³Ð¾ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ñ‹ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ ÑÑÑ‹Ð»ÐºÐ¸).

2. ÐœÐ¾Ð¶ÐµÑ‚ Ñ€Ð°ÑÑˆÐ¸Ñ€Ð¸Ñ‚ÑŒ ÑÐ²Ð¾Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¿Ð¾Ñ‚ÐµÐ½Ñ†Ð¸Ð»ÑŒÐ½Ñ‹Ñ… ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð¾Ð² Ð½Ð° ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ¹ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ðµ, Ð²Ñ‹Ð±Ñ€Ð°Ð² ÑÐ°Ð¼ÑƒÑŽ Ð»ÑƒÑ‡ÑˆÑƒÑŽ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñƒ Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ ÑÐ¿Ð¸ÑÐºÐ° ÑÐ°Ð¼Ñ‹Ñ… Ð¿Ð¾Ñ…Ð¾Ð¶Ð¸Ñ… Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼.

3. ÐœÐ¾Ð¶ÐµÑ‚ Ð¾Ð·Ð½Ð°ÐºÐ¾Ð¼Ð¸Ñ‚ÑŒÑÑ Ñ Ð½Ð°ÑˆÐµÐ¹ Ð±Ð°Ð·Ð¾Ð¹, Ð° Ð´Ð°Ð»ÑŒÑˆÐµ Ð¸Ð·ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¾Ð± ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð°Ñ… Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… ÑÑ‚Ñ€Ð°Ð½ Ð¸Ð· Ð±Ð°Ð·Ñ‹ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¸Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¾Ð².  

*ÐÐ° ÐºÐ°Ð¶Ð´Ð¾Ð¹ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ðµ Ð±ÑƒÐ´ÐµÑ‚ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ñ! ÐÐ°ÑˆÐ° Ñ‚ÐµÐ±Ðµ Ð´Ð°Ð¶Ðµ ÐµÑÐ»Ð¸ Ñ‚Ñ‹ ÑÐ¾Ð²ÑÐµÐ¼ Ð½Ðµ Ð·Ð½Ð°ÐµÑˆÑŒ Ñ‡ÐµÐ³Ð¾ Ñ‚Ñ‹ Ñ…Ð¾Ñ‡ÐµÑˆÑŒ!* 
            """
        )

        st.markdown("")

    col1, col2 = st.columns([5,5])
    with col1:
        with st.expander("Ð”Ð°Ð½Ð½Ñ‹Ðµ", expanded=False):

            st.markdown( """
            ÐŸÑ€Ð¾ÐµÐºÑ‚ Ð¾ÑÐ½Ð¾Ð²Ð°Ð½ Ð½Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ñ ÑÐ°Ð¹Ñ‚Ð° [masterstudies.ru](https://masterstudies.com). Ð¡Ð±Ð¾Ñ€ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¾ÐºÐ°Ð·Ð°Ð»ÑÑ Ð±Ð¾Ð»ÐµÐµ ÐºÐ¾Ð¼Ð»ÐµÐºÑÐ½Ð¾Ð¹ Ð·Ð°Ð´Ð°Ñ‡ÐµÐ¹, Ñ‡ÐµÐ¼ Ð¾Ð¶Ð¸Ð´Ð°Ð»Ð¾ÑÑŒ Ð¸Ð·Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½Ð¾. ÐŸÑ€Ð¾Ñ†ÐµÑÑ ÑÐ±Ð¾Ñ€Ð° ÑÐ¾ÑÑ‚Ð¾ÑÐ» Ð¸Ð· Ñ‚Ñ€Ñ‘Ñ… ÑÑ‚Ð°Ð¿Ð¾Ð²:

            *   Ð¡Ð±Ð¾Ñ€ ÑÑÑ‹Ð»Ð¾Ðº Ð½Ð° Ñ€Ð°Ð·Ð´ÐµÐ»Ñ‹ ÑÐ°Ð¹Ñ‚Ð° Ñ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð°Ð¼Ð¸ Ð¸Ð· Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¹ ('Ð­ÐºÐ¾Ð½Ð¾Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ñ','Ð£Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð±Ð¸Ð·Ð½ÐµÑÐ¾Ð¼', 'Ð•ÑÐµÑ‚ÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ðµ Ð½Ð°ÑƒÐºÐ¸' Ð¸ Ð´Ñ€ÑƒÐ³Ð¸Ðµ Ñ„ÑƒÐ½Ð´Ð°Ð¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð½Ñ‹Ðµ Ð² ÐÐ˜Ð£ Ð’Ð¨Ð­ (Ð¡ÐŸÐ±))
            *   Ð¡Ð±Ð¾Ñ€ Ð¾Ð±Ñ‰ÐµÐ¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¾ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð°Ñ… () Ð¸Ð· ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡ÐµÐº Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼ (Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñ‹, Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð°, Ð²Ð¸Ð´ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñ‹, Ð½Ð°Ñ‡Ð°Ð»Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¸ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñ‹, Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð¸ Ñ‚Ð¸Ð¿ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ, ÑÑ‚Ñ€Ð°Ð½Ð°, ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ, ÑÐ·Ñ‹Ðº Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ, Ð¸ Ð´ÐµÐ´Ð»Ð°Ð¹Ð½Ñ‹ Ð¿Ð¾Ð´Ð°Ñ‡Ð¸ Ð·Ð°ÑÐ²Ð¾Ðº)
            * Ð¡Ð±Ð¾Ñ€ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¸Ð· ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ† Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼ Ð½Ð° Keystone 

            Ð¡Ñ‹Ñ€Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ, ÐºÐ°Ðº Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð¾, Ð¿Ñ€Ð¾Ñ…Ð¾Ð´ÑÑ‚ Ð¿Ñ€Ð¾Ñ†ÐµÐ´ÑƒÑ€Ñƒ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¸, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð»Ð° Ð²Ð°Ð¶Ð½ÑƒÑŽ Ñ€Ð¾Ð»ÑŒ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ð½Ð°Ð´ Ñ„Ð¸Ñ‡Ð°Ð¼Ð¸. 
            * ÐœÑ‹ Ð¾Ñ‡Ð¸ÑÑ‚Ð¸Ð»Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¾Ñ‚ Ð²Ñ‹Ð±Ñ€Ð¾ÑÐ¾Ð², Ð¿Ñ€Ð¸Ð²ÐµÐ»Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð² ÑÑ‚Ð¾Ð»Ð±Ñ†Ð°Ñ… Ðº ÐµÐ´Ð¸Ð½Ð¾Ð¼Ñƒ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñƒ
            * ÐœÑ‹ ÑÐ¾Ð·Ð´Ð°Ð»Ð¸ Ð´Ð²Ð° Ð½Ð¾Ð²Ñ‹Ñ… Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð°: Ð¾Ð´Ð¸Ð½ Ñ Ð»Ð¾ÐºÐ°Ñ†Ð¸ÑÐ¼Ð¸ Ð¸ Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð½Ñ‹Ð¼Ð¸ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÑÐ¼Ð¸ Ð³Ð¾Ñ€Ð¾Ð´Ð¾Ð², Ð° Ð´Ñ€ÑƒÐ³Ð¾Ð¹ Ñ Ð±Ð»Ð¸Ð·Ð¾ÑÑ‚ÑŒÑŽ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ñ… Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ð¹ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼

            Ð’ Ð¸Ñ‚Ð¾Ð³Ðµ Ð±Ñ‹Ð» Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ñ‡Ð¸ÑÑ‚Ñ‹Ð¹ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ Ñ 6502 Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð°Ð¼Ð¸, Ð½Ð° ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð¾Ð¿Ð¸Ñ€Ð°ÐµÑ‚ÑÑ Ð½Ð°ÑˆÐµ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ.
    """, unsafe_allow_html = True)

            st.markdown("")
    with col2:
        with st.expander("MÐµÑ‚Ð¾Ð´Ñ‹ ", expanded=False):

            st.write(
                """

**Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð°**

Ð”Ð»Ñ Ð¿Ð¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ñ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð½Ð°Ð¼ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð»Ð¾ÑÑŒ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ *Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¾Ð³Ð¾* Ñ‚ÐµÐºÑÑ‚Ð° Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ð¹ Ð¼Ð°Ð³Ð¸ÑÑ‚ÐµÑ€ÑÐºÐ¸Ñ… Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼ Ð² ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð°Ñ…. Ð”Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ Ð±Ñ‹Ð»Ð° Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð° Ð²Ð°Ñ€Ð¸Ð°Ñ†Ð¸Ñ CBOW (continuous bag of words) Word2Vec, Ð´Ð¾ ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð¹ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð¿Ñ€Ð¾ÑˆÐ»Ð¸ Ð½ÐµÐ±Ð¾Ð»ÑŒÑˆÑƒÑŽ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÑƒ - Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ° Ð¾Ñ‚ ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð² Ð¸ Ñ†Ð¸Ñ„Ñ€, Ð»ÐµÐ¼Ð¼Ð°Ñ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ, Ñ‚Ð¾ÐºÐµÐ½Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¸ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ° Ð´Ð»Ñ Ð±Ð¾Ð»ÐµÐµ ÐºÐ¾Ñ€ÐµÐºÑ‚Ð½Ð¾Ð¹ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Word2Vec. Ð”Ð°Ð½Ð½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð±Ð¾Ð»ÐµÐµ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚ÐµÐ½ Ð² ÑÐ¸Ð»Ñƒ Ð¿Ñ€Ð¸Ð½Ñ†Ð¸Ð¿Ð° Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹, Ð¾ÑÐ½Ð¾Ð²Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð½Ð° Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¸ Ñ†ÐµÐ½Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ñ… ÑÐ»Ð¾Ð² Ð² Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ðµ Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ð¾ÐºÑ€ÑƒÐ¶Ð°ÑŽÑ‰Ð¸Ñ… ÐµÐ³Ð¾ ÑÐ»Ð¾Ð². Ð”Ð°Ð»ÐµÐµ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚ (Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ðµ Ð²Ð²Ð¾Ð´Ñ‹) Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÑŽÑ‚ÑÑ Ð² Ð²Ð¸Ð´Ðµ Ð¿Ñ€ÐµÐ¿Ñ€ÐµÐ·ÐµÐ½Ñ‚Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð²ÐµÐºÑ‚Ð¾Ñ€Ð¾Ð² Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¼ÐµÑ‚Ð¾Ð´Ð° IDF, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð½Ð°Ð·Ð½Ð°Ñ‡Ð°ÐµÑ‚ Ð¼ÐµÐ½ÑŒÑˆÐ¸Ð¹ Ð²ÐµÑ Ð±Ð¾Ð»ÐµÐµ Ñ€Ð°ÑÐ¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÐµÐ½Ð½Ñ‹Ð¼ ÑÐ»Ð¾Ð²Ð°Ð¼ -- ÑÑ‚Ð¾ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ‚ Ð½Ð°Ð¼ Ð´Ð¾ÑÑ‚Ð¸Ñ‡ÑŒ Ð±Ð¾Ð»ÑŒÑˆÐµÐ¹ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ ÑÐ¸Ð»Ñ‹ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð°. 

 * ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ðµ Ð²Ð²Ð¾Ð´Ñ‹

ÐœÑ‹ Ð½Ð°Ñ†ÐµÐ»ÐµÐ½Ñ‹ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð³Ð¾Ð²Ð¾Ñ€ÑÑ‰Ð¸Ñ… Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹, Ð¿Ð¾ÑÑ‚Ð¾Ð¼Ñƒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ðµ Ð²Ð²Ð¾Ð´Ñ‹ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð±Ñ‹Ñ‚ÑŒ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ. ÐŸÐ¾ ÑÑ‚Ð¾Ð¹ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ðµ, Ð¼Ñ‹ Ð²Ð½ÐµÐ´Ñ€Ð¸Ð»Ð¸ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ñ‡Ð¸ÐºÐ¸ Ñ‚ÐµÐºÑÑ‚Ð° Ñ Ñ€ÑƒÑÑÐºÐ¾Ð³Ð¾ Ð½Ð° Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº Ð´Ð»Ñ Ð¿Ð¾ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¸ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ð¸ ÑƒÐ¶Ðµ Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð° Ð¸ Ð¿Ð¾Ð´ÑÑ‡ÐµÑ‚Ð° ÐºÐ¾ÑÐ¸Ð½ÑƒÑÐ½Ñ‹Ñ… Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ð¹ Ð¼ÐµÐ¶Ð´Ñƒ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¼Ð¸ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð°Ð¼Ð¸ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ð¹ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼ Ð¸ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¼ Ð²Ð²Ð¾Ð´Ð¾Ð¼.

 * ÐŸÐ¾Ð¿Ð°Ñ€Ð½Ð¾Ðµ Ð²Ñ‹ÑÐ²Ð»ÐµÐ½Ð¸Ðµ ÑÑ…Ð¾Ð¶Ð¸Ñ… Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼

Ð”Ð»Ñ Ð´Ð¾Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ñ‹Ð¼Ð¸ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð°Ð¼Ð¸ Ð¼Ñ‹ Ð¿Ð¾ÑÑ‡Ð¸Ñ‚Ð°Ð»Ð¸ Ð½ÑƒÐ¶Ð½Ñ‹Ð¼ Ð²Ñ‹Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ ÑÑ…Ð¾Ð¶Ð¸Ñ… Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¿Ð¾Ð´ÑÑ‡ÐµÑ‚Ð° Ð¿Ð¾Ð¿Ð°Ñ€Ð½Ñ‹Ñ… ÐºÐ¾ÑÐ¸Ð½ÑƒÑÐ½Ñ‹Ñ… Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ð¹ Ð¼ÐµÐ¶Ð´Ñƒ Ð²ÑÐµÐ¼Ð¸ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð°Ð¼Ð¸ Ð² Ð±Ð°Ð·Ðµ. ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ðµ Ð¾Ð¿Ñ†Ð¸Ð¸ ÑÐ¾ ÑÑ…Ð¾Ð¶ÐµÑÑ‚ÑŒÑŽ Ð±Ð¾Ð»ÐµÐµ 0,65 (Ð¸Ð½Ð°Ñ‡Ðµ Ð±Ñ‹Ð»Ð¾ Ð±Ñ‹ ÑÐ»Ð¾Ð¶Ð½Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ñ Ð±Ð°Ð·Ð¾Ð¹ Ð¸Ð· >40 Ð¼Ð»Ð½ Ð¿Ð°Ñ€. 

 * Ð˜Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ð°Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ

ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑÐ¼ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ñ‹ Ð»Ð¾ÐºÐ°Ñ†Ð¸Ð¸ ÑÑ…Ð¾Ð¶Ð¸Ñ… Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼, Ð¿Ð¾ÑÑ‚Ð¾Ð¼Ñƒ Ð¼Ñ‹ Ð¿Ð¾ÑÑ‚Ñ€Ð¾Ð¸Ð»Ð¸ Ð¸Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ ÐºÐ°Ñ€Ñ‚Ñ‹ POI (Ð¸Ð»Ð¸ KDE-Ð¿Ð»Ð¾Ñ‚Ð½Ð¾ÑÑ‚ÑŒ Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ Ð³Ð¾Ñ€Ð¾Ð´Ð¾Ð² Ð½Ð° ÐºÐ°Ñ€Ñ‚Ðµ) Ð¸ Ð»Ð¾ÐºÐ°Ñ†Ð¸Ð¹ Ð´Ð»Ñ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð±Ð¾Ð»ÐµÐµ ÑˆÐ¸Ñ€Ð¾ÐºÐ¾Ð³Ð¾ Ð²Ñ‹Ð±Ð¾Ñ€Ð°.

""")

            st.markdown("")

    st.markdown("")
    #st.write(spread.url)

   # st.markdown(hello, unsafe_allow_html = True)

if page=='ÐÐ°Ð¹Ñ‚Ð¸ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼ÑƒðŸŒ':
    #_max_width_()
    c30, c31, c32 = st.columns([2.5, 1, 3])

    with c30:
        st.image("keystone-masters-degree.jpg", width=400)

    with st.expander("â„¹ï¸ - ÐžÐ± ÑÑ‚Ð¾Ð¹ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ðµ + Ð˜Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ñ", expanded=False):

        st.markdown("""
                ÐÐ° ÑÑ‚Ð¾Ð¹ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ðµ Ñ‚Ñ‹ ÑÐ¼Ð¾Ð¶ÐµÑˆÑŒ Ð¾Ð·Ð½Ð°ÐºÐ¾Ð¼Ð¸Ñ‚ÑŒÑÑ Ñ Ð±Ð»Ð¸Ð·ÐºÐ¸ Ñ‚Ð²Ð¾Ð¸Ð¼ Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ñ‡Ñ‚ÐµÐ½Ð¸ÑÐ¼Ð¸ Ñ‚Ð¸Ð¿Ð°Ð¼Ð¸ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼. Ð˜Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹Ñ Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¿Ñ€Ð¾ÑÑ‚ Ð² Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¸, Ð¿Ð¾ÑÑ‚Ð¾Ð¼Ñƒ Ñ€Ð°ÑÑÐºÐ°Ð¶ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¾ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð²Ð°Ð¶Ð½Ñ‹Ñ… Ð°ÑÐ¿ÐµÐºÑ‚Ð°Ñ… Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ. Ð£ Ñ‚ÐµÐ±Ñ ÐµÑÑ‚ÑŒ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¾Ð±Ñ‰Ð¸Ñ… Ð¸ Ð±Ð¾Ð»ÐµÐµ ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð·Ð°Ð²Ð¸ÑÑÑ‚ Ð¾Ñ‚ Ñ‚Ð²Ð¾Ð¸Ñ… Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ð¹.

                * Ð•ÑÐ»Ð¸ Ñ‚Ñ‹ Ð¶ÐµÐ»Ð°ÐµÑˆÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ *Ð²ÑÐµ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ðµ Ð¸Ð»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ñ‹*, Ñ‚Ð¾ Ñ‚ÐµÐ±Ðµ ÑÑ‚Ð¾Ð¸Ñ‚: ÐŸÐžÐ¡Ð¢ÐÐ’Ð˜Ð¢Ð¬ Ð“ÐÐ›ÐžÐ§ÐšÐ£ ÑÐ»ÐµÐ²Ð° Ð¾Ñ‚ 'Ð’Ñ‹ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸ÑŽ', Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼, Ð²Ð²ÐµÑÑ‚Ð¸ Ñ‚ÐµÐºÑÑ‚ Ð¾ ÑÐ²Ð¾Ð¸Ñ… Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ°Ñ…, ÑÐ¿Ð¾ÑÐ¾Ð±Ð½Ð¾ÑÑ‚ÑÑ… Ð¸Ð»Ð¸ Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸ÑÑ… - ÑÑ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð»ÑŽÐ±Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ, Ð½Ð°Ð¿Ð¸ÑÐ°Ð½Ð½Ñ‹Ð¹ Ð½Ð° ÐºÐ¸Ñ€Ð¸Ð»Ð»Ð¸Ñ†Ðµ. 

                * Ð•ÑÐ»Ð¸ Ð´ÐµÑ‚Ð°Ð»Ð¸ Ð²ÑÐµ-Ñ‚Ð°ÐºÐ¸ Ð²Ð°Ð¶Ð½Ñ‹, Ñ‚Ð¾ Ñ‚ÐµÐ±Ðµ ÑÑ‚Ð¾Ð¸Ñ‚ Ð·Ð°Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð²ÑÐµ Ð¿Ð¾Ð»Ñ Ñ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼Ð¸ Ð¸ Ð²Ð²ÐµÑÑ‚Ð¸ Ñ‚ÐµÐºÑÑ‚, Ð½Ð¾ ÐÐ• Ð¡Ð¢ÐÐ’Ð˜Ð¢Ð¬ Ð“ÐÐ›ÐžÐ§ÐšÐ£

                **ÐšÑ€Ð¾Ð¼Ðµ ÑÑ‚Ð¾Ð³Ð¾, Ð²Ð°Ð¶Ð½Ð¾ Ð·Ð°Ð¿Ð¾Ð¼Ð½Ð¸Ñ‚ÑŒ Ð¾Ð± Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ñ… ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð°Ñ… Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ°, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¼Ð¾Ð¶Ð½Ð¾ Ð±ÑƒÐ´ÐµÑ‚ ÑƒÐ²Ð¸Ð´ÐµÑ‚ÑŒ Ð² Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° -- Ñƒ Ñ‚ÐµÐ±Ñ Ð±ÑƒÐ´ÐµÑ‚ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ ÑÐºÑ€Ñ‹Ñ‚ÑŒ Ð¸Ð»Ð¸ Ñ€Ð°ÑÐºÑ€Ñ‹Ñ‚ÑŒ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ð¸ ÐºÐ°Ñ€Ñ‚Ñ‹.**
                
                Ð’ÐÐ–ÐÐž: Ð¯Ð·Ñ‹ÐºÐ¸ Ð¸ ÑÑ‚Ñ€Ð°Ð½Ñ‹ Ð¼Ð¾Ð¶Ð½Ð¾ Ð½Ð°Ð¹Ñ‚Ð¸ Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ð¼ Ð²Ð²Ð¾Ð´Ð¾Ð¼, Ñ‡Ñ‚Ð¾Ð±Ñ‹ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶Ð¸Ð»Ð° Ð°Ð²Ñ‚Ð¾Ð·Ð°Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ. 

                Ð¡Ð¿Ð°ÑÐ¸Ð±Ð¾ Ð·Ð° Ð¸Ð½Ñ‚ÐµÑ€ÐµÑ! Ð£Ð´Ð°Ñ‡Ð¸!  
        """)

        st.markdown("")

    st.markdown("")

    #scenario_interact = st.selectbox(
     #   "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÑÑ†ÐµÐ½Ð°Ñ€Ð¸Ð¹ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐ³Ð¾ Ð¾Ð¿Ñ‹Ñ‚Ð°",
      #  ["Ð¥Ð¾Ñ‡Ñƒ Ð½Ð°Ð¹Ñ‚Ð¸ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚", "Ð¥Ð¾Ñ‡Ñƒ Ñ€Ð°ÑÑˆÐ¸Ñ€Ð¸Ñ‚ÑŒ ÑÐ²Ð¾Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼"],
    

    with st.form(key="my_form"):

        ce, c1, ce, c2, c3 = st.columns([0.07, 2, 0.07, 4, 0.07])
        with c1:
            st.subheader('Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹') 
            number = st.number_input('Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ Ñ€ÐµÐºÐ¾Ð¼Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹ Ð¶ÐµÐ»Ð°ÐµÑˆÑŒ ÑƒÐ²Ð¸Ð´ÐµÑ‚ÑŒ Ð½Ð° ÑÐºÑ€Ð°Ð½Ðµ?', min_value=0, max_value=50, step=1, value=5)
            agree = st.checkbox('Ð’Ñ‹ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸ÑŽ')
            location = st.multiselect('Ð¡Ñ‚Ñ€Ð°Ð½Ð°', sorted(list(set(data['country'].dropna()))))
            dur = st.slider('ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ (Ð¼ÐµÑ)', int(data['duration_month'].min()), int(data['duration_month'].max()), (0, 10), step=2)
            on_site = st.selectbox('Ð¢Ð¸Ð¿ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ', ['ÐžÑ‡Ð½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ', 'Ð—Ð°Ð¾Ñ‡Ð½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ','ÐžÑ‡Ð½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ|Ð—Ð°Ð¾Ñ‡Ð½Ð¾Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ'])
            pace = st.selectbox('Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ', ['ÐžÐ½Ð»Ð°Ð¹Ð½', 'ÐšÐ°Ð¼Ð¿ÑƒÑ','ÐšÐ°Ð¼Ð¿ÑƒÑ|ÐžÐ½Ð»Ð°Ð¹Ð½'])
            lang = st.multiselect('Ð¯Ð·Ñ‹Ðº Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ', sorted(list(set(data['language'].dropna()))))
            cost = st.slider('Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð² Ð³Ð¾Ð´, EUR', int(data['tuition_EUR'].min()), int(data['tuition_EUR'].max()), (0, 8000), step=50)
        with c2:
             #to make row effects
            st.markdown('')
            st.markdown('')
            sentence = st.text_area("Ð’Ð²ÐµÐ´Ð¸ Ñ‚ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð²Ñ‹ÑÐ²Ð»ÐµÐ½Ð¸Ñ ÑÐ²Ð¾Ð¸Ñ… Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ñ‡Ñ‚ÐµÐ½Ð¸Ð¹ -- Ð¼Ð¾Ð¶ÐµÑˆÑŒ Ð²Ð²ÐµÑÑ‚Ð¸ Ñ‡Ñ‚Ð¾ ÑƒÐ³Ð¾Ð´Ð½Ð¾, Ð½Ð¾ Ñ†Ð¸Ñ„Ñ€Ñ‹ Ð¸ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹ Ð½Ðµ ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÑŽÑ‚ÑÑ Ð½Ð°ÑˆÐµÐ¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ð¾Ð¹", value='ÐÐ°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: Ñ Ð·Ð½Ð°ÑŽ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ, Ð¿Ñ€Ð¾ÑˆÐµÐ» ÐºÑƒÑ€ÑÑ‹ Ð¿Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑƒÑŽÑÑŒ Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ð¼Ð¸ Ñ€Ñ‹Ð½ÐºÐ°Ð¼Ð¸')
            submit = st.form_submit_button(label="âœ¨ ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸ÑŽ")
            corpus = list(clean_words)
            model = load_model('model_cbow.bin')
            model.init_sims(replace=True)
            tfidf_vec_tr = TfidfEmbeddingVectorizer(model)
            tfidf_vec_tr.fit(corpus)
            translator = Translator()
            result = translator.translate(sentence)
            text = result.text

    if not submit:
        st.stop()

    cmGreen = sns.light_palette("green", as_cmap=True)
    if submit:
        if len(text)==0:
            st.warning('Ð¢Ñ‹ Ð½Ðµ Ñ€Ð°ÑÑÐºÐ°Ð·Ð°Ð»(Ð°) Ð¾ ÑÐ²Ð¾Ð¸Ñ… Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ñ‡Ñ‚ÐµÐ½Ð¸ÑÑ…! Ð’ Ð´Ð°Ð½Ð½Ð¾Ð¼ ÑÐ»ÑƒÑ‡Ð°Ðµ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð²Ñ‹Ð´Ð°ÑÑ‚ Ð¿ÐµÑ€Ð²Ñ‹Ðµ {} ÑÑ‚Ñ€Ð¾Ðº(Ð¸) Ð½Ð°ÑˆÐµÐ¹ Ð±Ð°Ð·Ñ‹ Ñ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð°Ð¼Ð¸.... Ð­Ñ‚Ð¾ Ð½Ðµ Ð¾Ñ‡ÐµÐ½ÑŒ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾'.format(number))
            simple_output()
        else:
            if not agree:
                if len(location)>0 and len(lang)>0:  
                    col1, col2, col3 = st.columns([10, 10, 10])
                    with col1:
                        st.write('')
                    with col2:
                        gif_runner = st.image("200.gif")
                    with col3:
                        st.write('')
                    recs = get_recs(str(text), N=int(data.shape[0]), mean=False)
                    recs50 = get_recs(str(text), N=50, mean=False) #Ð²Ð¾Ñ‚ Ð·Ð´ÐµÑÑŒ Ð½Ð°Ð´Ð¾ Ð¸Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð¾ Ð²Ð²Ð¾Ð´ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð° Ð¶ÐµÐ»Ð°ÐµÐ¼Ñ‹Ñ… Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼, Ð° Ð¿Ð¾Ñ‚Ð¾Ð¼ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð²Ñ‹Ð´Ð°Ð²Ð°Ñ‚ÑŒ Ñ‚Ð¾Ð¿ 
                    gif_runner.empty()  
                    recs1 = recs[(recs['language'].isin(list(lang))) & (recs['country'].isin(list(location))) & (recs['on_site']==on_site) & (recs['format']==pace)  & (recs['tuition_EUR']>min(cost)) & (recs['tuition_EUR']<max(cost)) & (recs['duration_month']>min(dur)) & (recs['duration_month']<=max(dur))]
                    recs1 = recs1.reset_index().iloc[:number,:]
                    if recs1.shape[0]!=0:
                        recs2 = pick_n_pretty(recs1)
                        df = recs2.style.background_gradient(
                            cmap=cmGreen,
                            subset=[
                                "Score",
                            ],
                        )
                        st.write(df.to_html(escape=False), unsafe_allow_html=True)
                        map2 = mfap_density_50(recs50)
                        map  = mfap(recs2)
                        st.write('')
                        st.write('')
                        with st.expander('ÐŸÐ¾ÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒ Ð¸Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ ÐºÐ°Ñ€Ñ‚Ñ‹ðŸŒ'):
                            ce, c1, ce, c2, c3 = st.columns([0.07, 4, 0.07, 4, 0.07])
                            with c1:
                                st.write('Ð Ð°ÑÐ¿Ð¾Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ð·Ð°Ð¿Ñ€Ð°ÑˆÐ¸Ð²Ð°ÐµÐ¼Ñ‹Ñ… ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð¾Ð²')
                                folium_static(map, width=450) 
                            with c2:
                                st.write('POI-Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð³Ð¾Ñ€Ð¾Ð´Ð¾Ð² Ñ‚Ð¾Ð¿-50 Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼, ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ñ… Ñ‚Ð²Ð¾ÐµÐ¼Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÑƒ')
                                folium_static(map2, width=450)
                        if recs1.shape[0]<number:
                            st.warning("Ð£Ð¿Ñ... ÐŸÑ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼ Ð¼ÐµÐ½ÑŒÑˆÐµ Ñ‡ÐµÐ¼ Ð¾Ð¶Ð¸Ð´Ð°Ð»Ð¾ÑÑŒ, Ð½Ð¾ ÑÑ‚Ñƒ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñƒ Ð¼Ð¾Ð¶Ð½Ð¾ Ñ€ÐµÑˆÐ¸Ñ‚ÑŒ... ÐžÐ±Ñ€Ð°Ñ‚Ð¸ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ Ð½Ð° Ð¾Ð¿Ñ†Ð¸ÑŽ Ð½Ð¸Ð¶Ðµ)")
                            recs1 = recs.copy()
                            recs2 = pick_n_pretty(recs1)
                            map3 = mfap(recs2)
                            df = recs2.style.background_gradient(
                                cmap=cmGreen,
                                subset=[
                                    "Score",
                                ],
                            )
                            with st.expander('ÐŸÑ€ÐµÐ´Ð»Ð°Ð³Ð°ÐµÐ¼ Ð¾Ð·Ð½Ð°ÐºÐ¾Ð¼Ð¸Ñ‚ÑŒÑÑ Ñ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼Ð¸ Ð¾Ð¿Ñ†Ð¸ÑÐ¼Ð¸ Ð¸Ð· Ð½Ð°ÑˆÐµÐ¹ Ð±Ð°Ð·Ñ‹ ðŸ‘‰'):
                                st.write(df.to_html(escape=False), unsafe_allow_html=True)
                                C, D, E = st.columns([2,5,2])
                                with C:
                                    st.write('')
                                with D:
                                    st.write('Ð Ð°ÑÐ¿Ð¾Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð¾Ð² Ð¸Ð· Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð½Ð¾Ð¹ Ð²Ñ‹ÑˆÐµ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹')
                                    folium_static(map3)
                                with E:
                                    st.write('')

                            
                    else:
                        st.warning('ÐœÑ‹ Ð½Ðµ ÑÐ¼Ð¾Ð³Ð»Ð¸ Ð¿Ð¾Ð´Ð¾Ð±Ñ€Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñ‹, ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ Ñ‚Ð²Ð¾Ð¸Ð¼ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸ÑÐ¼, Ð½Ð¾ Ð¿Ñ€Ð¾ÑÐ¸Ð¼ Ð¾Ð·Ð½Ð°ÐºÐ¾Ð¼Ð¸Ñ‚ÑŒÑÑ Ñ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¼Ð¸ Ð² Ð½Ð°ÑˆÐµÐ¹ Ð±Ð°Ð·Ðµ ')
                        simple_output()
                else: 
                    st.warning('ÐœÑ‹ Ð½Ðµ ÑÐ¼Ð¾Ð³Ð»Ð¸ Ð¿Ð¾Ð´Ð¾Ð±Ñ€Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñ‹, ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ Ñ‚Ð²Ð¾Ð¸Ð¼ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸ÑÐ¼, Ð½Ð¾ Ð¿Ñ€Ð¾ÑÐ¸Ð¼ Ð¾Ð·Ð½Ð°ÐºÐ¾Ð¼Ð¸Ñ‚ÑŒÑÑ Ñ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¼Ð¸ Ð² Ð½Ð°ÑˆÐµÐ¹ Ð±Ð°Ð·Ðµ ')
                    simple_output()
                    # st.write('This is an error') #ÐÐ°Ð´Ð¾ Ð±ÑƒÐ´ÐµÑ‚ Ð¿Ð¾Ð»Ð½Ð¾ÑÑ‚ÑŒÑŽ Ð´Ð¾Ð¿Ð¸ÑÐ°Ñ‚ÑŒ

            else: 
                simple_output()
if page=='ÐÐ°Ð¹Ñ‚Ð¸ ÑÑ…Ð¾Ð¶Ð¸Ðµ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñ‹ðŸ™Œ':
    c30, c31, c32 = st.columns([2.5, 1, 3])

    with c30:
        st.image("keystone-masters-degree.jpg", width=400)

    with st.expander("â„¹ï¸ - ÐžÐ± ÑÑ‚Ð¾Ð¹ ÑÑ‚Ð°Ñ€Ð½Ð¸Ñ†Ðµ + Ð˜Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ñ", expanded=False):

        st.write("ÐÐ° ÑÑ‚Ð¾Ð¹ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ðµ Ñ‚Ñ‹ ÑÐ¼Ð¾Ð¶ÐµÑˆÑŒ Ð¾Ð·Ð½Ð°ÐºÐ¾Ð¼Ð¸Ñ‚ÑŒÑÑ Ñ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð°Ð¼Ð¸, Ð¿Ð¾Ñ…Ð¾Ð¶Ð¸Ð¼Ð¸ Ð½Ð° Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½ÑƒÑŽ Ñ‚Ð¾Ð±Ð¾Ð¹. Ð¢Ñ‹ Ð¼Ð¾Ð¶ÐµÑˆÑŒ Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ Ð¸Ð»Ð¸ Ð²Ð²ÐµÑÑ‚Ð¸ Ð¿ÐµÑ€Ð²Ñ‹Ðµ Ð±ÑƒÐºÐ²Ñ‹ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñ‹, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð°Ð¼Ð¸ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶Ð¸Ð»Ð° Ð°Ð²Ñ‚Ð¾Ð·Ð°Ð²Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ.")

        st.markdown("")

    st.markdown("")    

    st.write('Ð’Ñ‹Ð±ÐµÑ€Ð¸ Ð¾Ð´Ð½Ñƒ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñƒ Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ ÑÑ…Ð¾Ð¶Ð¸Ñ…')
    with st.form(key="my_form"):
        university_pick = st.selectbox("Ð¡Ð¿Ð¸ÑÐ¾Ðº ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ñ… Ð² Ð½Ð°ÑˆÐµÐ¹ Ð±Ð°Ð·Ðµ Ð¼Ð°Ð³Ð¸ÑÑ‚ÐµÑ€ÑÐºÐ¸Ñ… Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼", list(set(progs['Program1'].dropna())))
        number_sim = st.number_input('ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÑ…Ð¾Ð¶Ð¸Ñ… Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼', min_value=0, max_value=50, step=1, value=5)
        submit = st.form_submit_button(label="âœ¨ ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ñ‹")
        cmGreen = sns.light_palette("green", as_cmap=True)
    if submit:
        recs = sim_prog(progs, str(university_pick))
        map, recs0, ps = p2p_locs(recs=recs, N=number_sim) #ps is a dirty dataset
        df = recs0.sort_values(by='cosine', ascending=False).style.background_gradient(
            cmap=cmGreen,
            subset=[
                "cosine",
            ],
        )
        see_data = st.expander('ÐŸÐ¾ÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒ ÑÑ…Ð¾Ð¶Ð¸Ðµ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñ‹ ðŸ‘‰')
        with see_data:
            st.write(df.to_html(escape=False), unsafe_allow_html=True)
        st.write('')
        ce, c1, ce, c2, c3 = st.columns([0.07, 4, 0.07, 4, 0.07])
        with c1:
            st.write('Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ ÑÑ…Ð¾Ð¶Ð¸Ñ… Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼')
            folium_static(map, width=500)
        with c2:
            st.write('')
            c_metric = ps.groupby('Program1')['Program2'].count()[0]
            st.metric(label='Ð¡Ñ…Ð¾Ð¶Ð¸Ñ… Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼', value='{}'.format(c_metric))
            d_metric = ps[ps.Uni==ps.Uni1].shape[0]
            st.metric(label='Ð’ Ð¾Ð´Ð½Ð¾Ð¼ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ðµ', value='{}'.format(d_metric))
            top = ps.groupby(['city'])['Program2'].agg(['count']).sort_values(by = 'count', ascending=False)
            df = pd.DataFrame({'Ð“Ð¾Ñ€Ð¾Ð´':list(top.index), 'ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾': list(top['count'])})
            with st.expander('Ð’ÑÑ‚Ñ€ÐµÑ‡Ð°ÐµÐ¼Ð¾ÑÑ‚ÑŒ ÑÑ‚Ñ€Ð°Ð½ ÑÑ…Ð¾Ð¶Ð¸Ñ… Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼', expanded=True):
                st.dataframe(data=df)
            st.text('')



   
if page == 'Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð¸ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°ðŸ“ˆ':
    #_max_width_()
    #data = pd.read_excel('main_data-2.xlsx', index_col=0)
    c30, c31, c32 = st.columns([2.5, 1, 3])

    with c30:
        st.image("keystone-masters-degree.jpg", width=400)


        st.markdown("")
    see_data = st.expander('ÐŸÐ¾ÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ ðŸ‘‰')
    with see_data:
        data['duration_month'] = data['duration_month'].astype('str')
        st.dataframe(data=data)
    st.text('')

    with st.expander('ÐžÐ±Ñ‰Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°'):

        col1, col2, col3, col4, col5, col6, col7 = st.columns([1,4,1,4,1,4,1])
        qprogs, qcountry, quni = data.shape[0], len(set(data['country'])), len(set(data['university'])) 
        col1.write('')
        col2.metric("Ð¡Ñ‚Ñ€Ð°Ð½ ðŸŒ", "{}".format(qcountry))
        col3.write('')
        col4.metric("Ð£Ð½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð¾Ð² ðŸŽ“","1440") #"{}".format(quni))
        col5.write('')
        col6.metric("ÐŸÑ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñ‹ ðŸš€", "6502")#"{}".format(qprogs))
        col7.write('')

        st.write('')

        data1 = data.groupby('country').count().reset_index().sort_values(by='Link', ascending=False).head(6)
        data2 = data.groupby('format').count().reset_index()

        ce, c1, ce, c2, c3 = st.columns([0.07, 4, 0.07, 4, 0.07])
        with c1:
            fig1 = px.pie(data1, names='country', values='Link', color_discrete_sequence=px.colors.sequential.RdBu, labels={
                        "country": "Ð¡Ñ‚Ñ€Ð°Ð½Ð°",
                        "n": "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÐ²Ð¾ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼",
                    }, title='Ð¢ÐžÐŸ-ÑÑ‚Ñ€Ð°Ð½ Ð¿Ð¾ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ñƒ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼',  width=600, height=400)
            fig1.update_layout(paper_bgcolor="black",
                                font_color="white")
            st.plotly_chart(fig1, use_container_width=True)

        with c2:
            fig2 = px.pie(data2, names='format', values='Link', color_discrete_sequence=px.colors.diverging.RdYlGn, labels={
                        "format": "Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚",
                        "n": "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÐ²Ð¾ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼",
                    }, title='Ð¡Ð¾Ð¾Ñ‚Ð½Ð¾ÑˆÑ‰ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼ Ð¿Ð¾ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð°Ð¼ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ',  width=600, height=400)
            fig2.update_layout(paper_bgcolor="black",
                                font_color="white")
            st.plotly_chart(fig2, use_container_width=True)
        data['duration_month'] = data['duration_month'].astype('float32')
        data3 = data.groupby('country')['tuition_EUR'].agg(['mean']).reset_index().sort_values(by='mean', ascending=True).head(43)
        data4 = data.groupby('country')['duration_month'].agg(['mean']).reset_index().sort_values(by='mean', ascending=False).head(45)
        ce, c1, ce, c2, c3 = st.columns([0.07, 4, 0.07, 4, 0.07])
        with c1:
            fig3 = px.bar(data3, x = "mean", y = "country", orientation='h', labels={
                                "mean": "Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ",
                                "country": "Ð¡Ñ‚Ñ€Ð°Ð½Ð°"
                            }, title='Ð¡Ñ€ÐµÐ´Ð½ÑÑ ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¿Ð¾ ÑÑ‚Ñ€Ð°Ð½Ð°Ð¼')
            fig3.update_traces(marker_color='red', marker_line_color='red',
                            marker_line_width=1, opacity=1)
            fig3.update_layout(legend_font_size=1, width=800,
                height=900, paper_bgcolor="black", font_color='white')
            st.plotly_chart(fig3, use_container_width=True)

        with c2:
            fig6 = px.bar(data4, x = "mean", y = "country", orientation='h', text_auto=True, labels={
                                "mean": "Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ (Ð¼ÐµÑ)",
                                "country": "Ð¡Ñ‚Ñ€Ð°Ð½Ð°",
                            }, title='Ð¡Ñ€ÐµÐ´Ð½ÑÑ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ')
            fig6.update_traces(marker_color='red', marker_line_color='red',
                            marker_line_width=1, opacity=1)
            fig6.update_layout(yaxis=dict(autorange="reversed"), legend_font_size=1, width=700,
                height=900, paper_bgcolor="black", font_color='white')
            st.plotly_chart(fig6, use_container_width=True)
        
    st.write('')

    st.write('Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÑÑ‚Ñ€Ð°Ð½Ñƒ Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð±Ð¾Ð»ÑŒÑˆÐµÐ³Ð¾ Ð¾Ð±ÑŠÐµÐ¼Ð° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¾Ð± ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð°Ñ…')
        
    with st.form(key="my_form"):
        country = st.selectbox("Ð¡Ð¿Ð¸ÑÐ¾Ðº ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ñ… Ð² Ð½Ð°ÑˆÐµÐ¹ Ð±Ð°Ð·Ðµ ÑÑ‚Ñ€Ð°Ð½", list(set(data['country'].dropna())))
        submit = st.form_submit_button(label="âœ¨ ÐŸÐ¾Ð´Ñ‚Ð²ÐµÑ€Ð´Ð¸Ñ‚ÑŒ Ð²Ñ‹Ð±Ð¾Ñ€")
    if submit:
        data_gb = data[data['country']==country]
        with st.expander('{} - Ð·Ð°Ð¼ÐµÑ‡Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€!'.format(country)):
            data_f = data_gb.groupby('format').count().reset_index()
            data_l = data_gb.groupby('language').count().reset_index()
            ce, c1, ce, c2, c3 = st.columns([0.07, 4, 0.07, 4, 0.07])
            with c1:
                figf = px.pie(data_f, names='format', values='Link', color_discrete_sequence=px.colors.sequential.RdBu, labels={
                            "format": "Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚",
                            "Link": "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÐ²Ð¾ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼",
                        }, title='Ð¡Ð¾Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼ Ð¿Ð¾ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð°Ð¼ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ',  width=600, height=400)
                figf.update_layout(paper_bgcolor="black",
                                    font_color="white")
                st.plotly_chart(figf, use_container_width=True)

            with c2:
                figl = px.pie(data_l, names='language', values='Link', color_discrete_sequence=px.colors.diverging.RdYlGn, labels={
                            "language": "Ð¯Ð·Ñ‹Ðº Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ",
                            "Link": "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÐ²Ð¾ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼",
                        }, title='Ð¡ÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ ÑÐ·Ñ‹ÐºÐ¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ',  width=600, height=400)
                figl.update_layout(paper_bgcolor="black",
                                    font_color="white")
                st.plotly_chart(figl, use_container_width=True)
            
            st.write('')
            data_count = data_gb.groupby('university').count().reset_index().sort_values(by='Link', ascending=False).head(60)
            data_cost = data_gb.groupby('university')['tuition_EUR'].agg(['mean']).reset_index().sort_values(by='mean', ascending=False).head(60)
            c1, c2, c3 = st.columns([0.05, 6 ,0.05])
            with c2:
                fig10 = px.bar(data_count, x = "Link", y = "university", orientation='h', text_auto=True, labels={
                     "Link": "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼ Ð² ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ðµ",
                     "university": "Ð£Ð½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚",
                 }, title='Ð’ÑÑ‚Ñ€ÐµÑ‡Ð°ÐµÐ¼Ð¾ÑÑ‚ÑŒ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼ Ð² ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð°Ñ…')

                fig10.update_traces(marker_color='red', marker_line_color='red',
                                marker_line_width=1, opacity=1)

                fig10.update_layout(yaxis=dict(autorange="reversed"), legend_font_size=1, width=1000,
                    height=1100,  paper_bgcolor="black", font_color='white')
                st.plotly_chart(fig10, use_container_width=True)
            
            st.write('')

            c1, c2, c3 = st.columns([0.05, 6 ,0.05])
            with c2:
                fig8 = px.bar(data_cost.dropna(), x = "mean", y = "university", orientation='h', text_auto=True, labels={
                        "mean": "Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸ (EUR/Ð³Ð¾Ð´)",
                        "university": "Ð£Ð½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚",
                    }, title='Ð¡Ñ€ÐµÐ´Ð½ÑÑ ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð² ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð°Ñ…')

                fig8.update_traces(marker_color='red', marker_line_color='red',
                    marker_line_width=1, opacity=1)

                fig8.update_layout(yaxis=dict(autorange="reversed"), legend_font_size=1, width=1000,
                        height=1100,  paper_bgcolor="black", font_color='white')
                st.plotly_chart(fig8, use_container_width=True)
            

                


            
